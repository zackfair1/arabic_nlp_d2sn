{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conspiracy Dataset</h1>\n",
    "Dans ce dataset, je vais analyser encore une fois les topics, et finir par entrainer un ou plusieurs modèles de Huggingface<br>\n",
    "<h3>This notebook is for Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import re, os, nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Simple preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51087/51087 [00:00<00:00, 107058.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قال تعالى(إنّهُم يَرَوْنَهُ بعيداًونَراهُ قريبا)</td>\n",
       "      <td>قال تعالى إنّهُم يَرَوْنَهُ بعيداًونَراهُ قريبا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الجيش الروسي يباد في مدينة إيربين الآن</td>\n",
       "      <td>الجيش الروسي يباد في مدينة إيربين الآن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لم يتبقى الا سنوات قليلة..\\nhttps://t.me/orkSu...</td>\n",
       "      <td>لم يتبقى الا سنوات قليلة</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>لم نسمع منذ فترة عن هجمات داعش في افغانستان \\n...</td>\n",
       "      <td>لم نسمع منذ فترة عن هجمات داعش في افغانستان سي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>الولايات المتحدة تخطط لدعم طالبان ضد داعش 🔴\\n\\...</td>\n",
       "      <td>الولايات المتحدة تخطط لدعم طالبان ضد داعش مسرح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#للتذكير</td>\n",
       "      <td>للتذكير</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  \\\n",
       "0   قال تعالى(إنّهُم يَرَوْنَهُ بعيداًونَراهُ قريبا)   \n",
       "1             الجيش الروسي يباد في مدينة إيربين الآن   \n",
       "2  لم يتبقى الا سنوات قليلة..\\nhttps://t.me/orkSu...   \n",
       "7  لم نسمع منذ فترة عن هجمات داعش في افغانستان \\n...   \n",
       "8  الولايات المتحدة تخطط لدعم طالبان ضد داعش 🔴\\n\\...   \n",
       "9                                           #للتذكير   \n",
       "\n",
       "                                                 txt  \n",
       "0    قال تعالى إنّهُم يَرَوْنَهُ بعيداًونَراهُ قريبا  \n",
       "1             الجيش الروسي يباد في مدينة إيربين الآن  \n",
       "2                           لم يتبقى الا سنوات قليلة  \n",
       "7  لم نسمع منذ فترة عن هجمات داعش في افغانستان سي...  \n",
       "8  الولايات المتحدة تخطط لدعم طالبان ضد داعش مسرح...  \n",
       "9                                            للتذكير  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main dataframe without NaN\n",
    "df = pd.read_csv('texts.csv').dropna()\n",
    "# Only arabic characters (no punctuations too)\n",
    "df['txt'] = df.texts.progress_map(lambda x : ' '.join(re.findall(r'[\\u0600-\\u06FF]+', x)))\n",
    "# Drop empty values (FINAL DF)\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True).dropna()\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Textes de la colonne txt du dataframe & prétraitement / lemmatisation</h4>\n",
    "<p>Cette fois, je vais utiliser Qalsadi, il est assez précis et beaucoup plus rapide que Farasa (il faut quand même 20 à 30 minutes...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['أكل', 'تفاح']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to lemmatize\n",
    "import qalsadi.lemmatizer\n",
    "lemmer = qalsadi.lemmatizer.Lemmatizer()\n",
    "def lemmatize(text):\n",
    "    output = []\n",
    "    if type(text) == list:\n",
    "        for word in text:\n",
    "            output.append(lemmer.lemmatize(word))\n",
    "        return output\n",
    "    else:\n",
    "        return lemmer.lemmatize(text)\n",
    "# Test\n",
    "lemmatize(['أكلت','تفاحتان'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45065/45065 [00:00<00:00, 176276.95it/s]\n",
      "100%|██████████| 32662/32662 [1:00:42<00:00,  8.97it/s] \n"
     ]
    }
   ],
   "source": [
    "# # Corpus with documents containing more than 4 words\n",
    "# texts = [text.split(' ') for text in tqdm(df.txt) if len(text.split(' ')) > 4]\n",
    "\n",
    "# # Lemmatize the corpus\n",
    "# lemmatized = [lemmatize(doc) for doc in tqdm(texts)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Exporter les données sous lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Export the dataframe\n",
    "# # pd.DataFrame({'text':texts, 'lemmatized':lemmatized}).to_csv('lemmatized_texts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a90448524f656655376e589a7c5d3deb138177bb112388cb30ddfc6b5ff35d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
